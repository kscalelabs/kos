syntax = "proto3";

package kos.inference;

import "google/protobuf/empty.proto";
import "kos/common.proto";

option go_package = "kos/inference;inference";
option java_package = "com.kos.inference";
option csharp_namespace = "KOS.Inference";

// The InferenceService allows uploading models and running inference.
service InferenceService {
    // Uploads a model to the robot.
    rpc UploadModel(UploadModelRequest) returns (UploadModelResponse);

    // Loads models from the robot's filesystem.
    rpc LoadModels(ModelUids) returns (LoadModelsResponse);

    // Unloads models from the robot's filesystem.
    rpc UnloadModels(ModelUids) returns (kos.common.ActionResponse);

    // Get available models
    rpc GetModelsInfo(GetModelsInfoRequest) returns (GetModelsInfoResponse);

    // Runs inference using a specified model.
    rpc Forward(ForwardRequest) returns (ForwardResponse);
}

// Request message for uploading a model.
message UploadModelRequest {
    bytes model = 1; // Model binary data
    optional ModelMetadata metadata = 2; // Model metadata
}

// Response message containing the uploaded model's UID.
message UploadModelResponse {
    string model_uid = 1;           // Unique identifier for the model
    kos.common.Error error = 2; // Error details if upload failed
}

// Response message containing the loaded models.
message LoadModelsResponse {
    repeated ModelInfo models = 1; // List of loaded models
    kos.common.ActionResponse result = 2; // Result of the action
}

// Request message for getting all available models
message GetModelsInfoRequest {
    oneof filter {
        ModelUids model_uids = 1; // List of specific model UIDs to fetch
        bool all = 2;             // If true, return all models
    }
}

// List of model UIDs
message ModelUids {
    repeated string uids = 1;
}

// Response message containing all available models
message GetModelsInfoResponse {
    repeated ModelInfo models = 1; // List of model information
    kos.common.Error error = 2; // Error details if fetching failed
}

// Model metadata
message ModelMetadata {
    optional string model_name = 1; // Model name
    optional string model_description = 2; // Model description
    optional string model_version = 3; // Model version
    optional string model_author = 4; // Model author
}

// Information about a model
message ModelInfo {
    string uid = 1;                            // Model UID (assigned by server)
    ModelMetadata metadata = 2;                // Model metadata
    map<string, Tensor> input_specs = 3;       // Expected input tensor specifications
    map<string, Tensor> output_specs = 4;      // Expected output tensor specifications
    string description = 5;                    // Optional description of tensor usage
}

// Request message for running inference.
message ForwardRequest {
    string model_uid = 1;        // Model UID to use for inference
    map<string, Tensor> inputs = 2;   // Named input tensors
}

// A tensor containing data
message Tensor {
    repeated float values = 1;   // Tensor values in row-major order
    repeated Dimension shape = 2; // Shape of the tensor

    // Dimension information
    message Dimension {
        uint32 size = 1;        // Size of this dimension
        string name = 2;        // Name (e.g., "batch", "channels", "height")
        bool dynamic = 3;       // Whether this dimension can vary (e.g., batch size)
    }
}

// Response message containing inference results.
message ForwardResponse {
    map<string, Tensor> outputs = 1;   // Named output tensors
    kos.common.Error error = 2;   // Error details if inference failed
}
